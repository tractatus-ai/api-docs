---
title: "Query Inference Results"
sidebarTitle: "Query Inference Results"
description: "Poll the status and results for an inference that has already started."
openapi: "GET /deploy/endpoint/{endpoint_id}/result/{inference_id}"
api: "GET /deploy/endpoint/{endpoint_id}/result/{inference_id}"
---

<ResponseExample>

```json Response
{
    "request_id": "30e66a7e-22c2-41fd-97fb-6db3e86b3ed1"
    "inference_id": "a44084ab-30f3-43af-be0c-048ee8852697",
    "created_at": "2023-06-21T01:13:57.254678+00:00",
    "modified_at": "2023-06-21T01:14:03.235466+00:00",
    "status": "COMPLETED",
    "message": "Inference completed successfully",
    "output_type": "text",
    "output_format": "text",
    "output": "This is the output from the Large-Language Model",
    "latency_ms": 5985,
}
```


  ```json Validation Error
  {
    "detail": [
      {
        "loc": [
          "path",
          "inference_id"
        ],
        "msg": "value is not a valid uuid",
        "type": "type_error.uuid"
      }
    ]
  }
  ```


</ResponseExample>